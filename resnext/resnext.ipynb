{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "resnext.ipynb",
      "provenance": [],
      "mount_file_id": "1wAD8vabCdOyUvIh5E_8nwgvEgDOEVDMp",
      "authorship_tag": "ABX9TyPPaN03VrEMEVe9nvTPk/3k"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mgtx19dbmplr"
      },
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "root_path = '/gdrive/MyDrive/cnn-architectures/resnext'\n",
        "path = '/content/gdrive/MyDrive/cnn-architectures/resnext'\n",
        "os.chdir(path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VkwKtF-tobeP"
      },
      "source": [
        "Standard imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_lrX31tnoa6w"
      },
      "source": [
        "import torch\n",
        "\n",
        "from torchsummary import summary\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torch.backends.cudnn as cudnn\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SfPh-1G7oW8I"
      },
      "source": [
        "Grouped convolution block"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NpOhzmfwoYj1"
      },
      "source": [
        "class Block(nn.Module):\n",
        "\n",
        "    expansion = 2\n",
        "\n",
        "    def __init__(self, in_planes, cardinality=32, bottleneck_width=4, stride=1):\n",
        "        super(Block, self).__init__()\n",
        "        group_width = cardinality * bottleneck_width\n",
        "        self.conv1 = nn.Conv2d(in_planes, group_width, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(group_width)\n",
        "        self.conv2 = nn.Conv2d(group_width, group_width, kernel_size=3, stride=stride, padding=1, groups=cardinality, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(group_width)\n",
        "        self.conv3 = nn.Conv2d(group_width, self.expansion*group_width, kernel_size=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(self.expansion*group_width)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion*group_width:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion*group_width, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion*group_width)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = F.relu(self.bn2(self.conv2(out)))\n",
        "        out = self.bn3(self.conv3(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Asi1Xr6o40e"
      },
      "source": [
        "ResNext class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qEfpBEu3o7a2"
      },
      "source": [
        "class ResNeXt(nn.Module):\n",
        "    def __init__(self, num_blocks, cardinality, bottleneck_width, num_classes=10):\n",
        "        super(ResNeXt, self).__init__()\n",
        "        self.cardinality = cardinality\n",
        "        self.bottleneck_width = bottleneck_width\n",
        "        self.in_planes = 64\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.layer1 = self._make_layer(num_blocks[0], 1)\n",
        "        self.layer2 = self._make_layer(num_blocks[1], 2)\n",
        "        self.layer3 = self._make_layer(num_blocks[2], 2)\n",
        "        self.linear = nn.Linear(cardinality*bottleneck_width*8, num_classes)\n",
        "\n",
        "    def _make_layer(self, num_blocks, stride):\n",
        "        strides = [stride] + [1]*(num_blocks-1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(Block(self.in_planes, self.cardinality, self.bottleneck_width, stride))\n",
        "            self.in_planes = Block.expansion * self.cardinality * self.bottleneck_width\n",
        "\n",
        "        # Increase bottleneck_width by 2 after each stage.\n",
        "        self.bottleneck_width *= 2\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = F.avg_pool2d(out, 8)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QJTdk3N-pvh-"
      },
      "source": [
        "Define ResNeXt model function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cd-HcO0Kpxwb"
      },
      "source": [
        "def ResNeXt29_4x64d():\n",
        "    return ResNeXt(num_blocks=[3,3,3], cardinality=4, bottleneck_width=64)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TGAcCJ4dyxI6"
      },
      "source": [
        "Some initial setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQPwvtlYy2cf"
      },
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "best_acc = 0 #best test accuracy\n",
        "start_epoch = 0 #start from epoch 0 or last checkpoint epoch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BCAsQLEEz77b"
      },
      "source": [
        "Perform data augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cUce77GL0BMN"
      },
      "source": [
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(\n",
        "    root='./data', train=True, download=True, transform=transform_train)\n",
        "trainloader = torch.utils.data.DataLoader(\n",
        "    trainset, batch_size=128, shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(\n",
        "    root='./data', train=False, download=True, transform=transform_test)\n",
        "testloader = torch.utils.data.DataLoader(\n",
        "    testset, batch_size=100, shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer',\n",
        "           'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bprf0e7S1Ha0"
      },
      "source": [
        "Transfer to GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xm_RMgvt0Sbf"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") \n",
        "net = ResNeXt29_4x64d().to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nmEblT5M6Lq1"
      },
      "source": [
        "Define loss function and optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8T-_w0O6Nps"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss() #cross-entropy loss\n",
        "optimizer = optim.SGD(net.parameters(), lr = 0.1, momentum=0.9, weight_decay=5e-4) #SGD \n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200) #LR scheduler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yuhkVxpR1F3H"
      },
      "source": [
        "Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7pcqWWI1JpA"
      },
      "source": [
        "def train(epoch):\n",
        "    print('\\nEpoch: %d' % epoch)\n",
        "    net.train()\n",
        "    train_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    \n",
        "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "        print((batch_idx, len(trainloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
        "                     % (train_loss/(batch_idx+1), 100.*correct/total, correct, total)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DqnqDSkO1SiT"
      },
      "source": [
        "Test the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4w5DDrf1T5O"
      },
      "source": [
        "def test(epoch):\n",
        "    global best_acc\n",
        "    net.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            test_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "            print((batch_idx, len(testloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
        "                         % (test_loss/(batch_idx+1), 100.*correct/total, correct, total)))\n",
        "\n",
        "    # Save checkpoint only if there's an improvement\n",
        "    acc = 100.*correct/total\n",
        "    if acc > best_acc:\n",
        "        print('Saving..')\n",
        "        state = {\n",
        "            'net': net.state_dict(),\n",
        "            'acc': acc,\n",
        "            'epoch': epoch,\n",
        "        }\n",
        "        if not os.path.isdir('checkpoint'):\n",
        "            os.mkdir('checkpoint')\n",
        "        torch.save(state, './checkpoint/ckpt.pth')\n",
        "        best_acc = acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FmI_wIek49RK"
      },
      "source": [
        "Model summary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YWeA-nFg4-Sy"
      },
      "source": [
        "summary(net, (3,32,32))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Peuph7wO1X-a"
      },
      "source": [
        "Run the model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N7VNpuNW1exB"
      },
      "source": [
        "for epoch in range(start_epoch, start_epoch+150):\n",
        "    train(epoch)\n",
        "    test(epoch)\n",
        "    scheduler.step()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}